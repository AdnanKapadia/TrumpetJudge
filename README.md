# ğŸº TrumpetJudge

AI-powered feedback for trumpet performances. Upload or record a trumpet clip and get instant scores on 5 dimensions of playing quality.

## Features

- **Instant AI Feedback** - Get scores in seconds, not days
- **5 Scoring Dimensions**:
  - ğŸ¯ **Intonation** - Pitch accuracy and tuning
  - ğŸµ **Tone Quality** - Warmth, clarity, and richness
  - â±ï¸ **Timing** - Rhythmic accuracy and steadiness
  - ğŸ¼ **Technique** - Articulation, dynamics, and control
  - â­ **Overall** - General performance quality
- **Web Interface** - Upload files or record directly from your browser
- **Personalized Tips** - Get improvement suggestions based on your weakest areas

## Quick Start

### 1. Install Dependencies

```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Run the Demo App

```bash
python demo/run_demo.py
```

This launches a web interface where you can upload or record trumpet audio and get instant feedback.

## Project Structure

```
TrumpetJudge/
â”œâ”€â”€ demo/
â”‚   â””â”€â”€ run_demo.py        # ğŸº Main demo app - upload/record and get scores
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ train.py           # Train the regression model
â”‚   â”œâ”€â”€ predict.py         # Run inference on audio files
â”‚   â”œâ”€â”€ dataset.py         # PyTorch dataset for trumpet audio
â”‚   â”œâ”€â”€ prepare_data.py    # Prepare train/val splits from labels
â”‚   â””â”€â”€ eval.py            # Model evaluation
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ encoder_panns.py   # PANNs CNN14 audio encoder (frozen)
â”‚   â””â”€â”€ head_regressor.py  # Trainable regression head
â”œâ”€â”€ label/
â”‚   â””â”€â”€ app.py             # Gradio UI for human labelers
â”œâ”€â”€ dsp/
â”‚   â”œâ”€â”€ tuning_analysis.py # Pitch/intonation analysis
â”‚   â”œâ”€â”€ rhythm_analysis.py # Timing analysis
â”‚   â”œâ”€â”€ sheet_music.py     # Generate sheet music from audio
â”‚   â””â”€â”€ plots.py           # Visualization utilities
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ audio/             # Audio chunks for training
â”‚   â”œâ”€â”€ labels/            # Human labels (per-labeler CSVs)
â”‚   â”œâ”€â”€ prepared/          # Prepared train/val splits
â”‚   â””â”€â”€ check_audio/       # Test audio files
â”œâ”€â”€ checkpoints/           # Saved model weights
â””â”€â”€ requirements.txt
```

## How It Works

### Architecture

```
Audio (WAV) â†’ PANNs CNN14 Encoder â†’ 2048-dim embedding â†’ Regression Head â†’ 5 scores
              (frozen, pretrained)                      (trained on labels)
```

1. **PANNs Encoder**: Pretrained audio neural network (CNN14) extracts rich audio features. This is frozen during training.
2. **Regression Head**: Small MLP trained on human-labeled trumpet performances to predict 5 quality scores.

### Training Pipeline

1. **Collect Data**: Download trumpet performances from YouTube
2. **Chunk Audio**: Split into 20-second clips
3. **Label**: Human raters score each clip (1-5) on 5 dimensions
4. **Train**: Fine-tune regression head on labeled data
5. **Evaluate**: Check MAE on held-out validation set

## Usage

### Training a Model

```bash
# Prepare data from labels
python ml/prepare_data.py --labels data/labels/labels_yourname.csv

# Train the model
python ml/train.py --train_csv data/prepared/train.csv --val_csv data/prepared/val.csv
```

### Running Inference

```bash
# CLI inference
python ml/predict.py --audio path/to/trumpet.wav

# Or use the web demo
python demo/run_demo.py
```

### Labeling Data

```bash
# Launch the labeling UI
python label/app.py
```

This opens a web interface where labelers can:
- Listen to audio clips
- Rate on 5 dimensions (1-5 scale)
- Reject invalid clips
- Track progress

## Scoring Guide

| Score | Description |
|-------|-------------|
| 5 | Excellent - Professional quality |
| 4 | Good - Minor issues, mostly solid |
| 3 | Average - Noticeable problems but acceptable |
| 2 | Below Average - Significant issues |
| 1 | Poor - Major problems throughout |

### Dimension Definitions

- **Overall**: Your gut feeling about the performance quality
- **Intonation**: Is it in tune? Are intervals accurate?
- **Tone**: Does it sound good? Warm, clear, resonant?
- **Timing**: Is the rhythm steady? Are rhythms accurate?
- **Technique**: Clean articulation? Good dynamics? Control?

## Requirements

- Python 3.8+
- PyTorch 2.0+
- ~500MB disk space for PANNs model weights (downloaded automatically)
- GPU recommended but not required

## Development

### Adding More Training Data

1. Add YouTube URLs to `data/youtube_urls.csv`
2. Download and chunk audio (creates entries in `data/to_label.csv`)
3. Run labeling app and rate clips
4. Prepare data and retrain

### DSP Analysis (Experimental)

```bash
# Analyze tuning/pitch of an audio file
python dsp/tuning_analysis.py
```

Generates pitch contour plots, note-by-note tuning analysis, and sheet music transcription.

## License

MIT

## Acknowledgments

- [PANNs](https://github.com/qiuqiangkong/audioset_tagging_cnn) - Pretrained audio neural networks
- [Gradio](https://gradio.app) - Web UI framework
- [librosa](https://librosa.org) - Audio analysis
